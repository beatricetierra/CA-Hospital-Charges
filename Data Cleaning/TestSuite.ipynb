{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run DataCleaning.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "import pandas\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "import azure.storage.blob\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from pyspark.sql.types import StructField, StructType, StringType, FloatType, IntegerType, ShortType\n",
    "\n",
    "class TestDataCleaning(unittest.TestCase):\n",
    "    \n",
    "    @classmethod\n",
    "    def setUpClass(cls):\n",
    "        global blob_service_client, container1, container2, container3, \\\n",
    "        blob_location1, blob_location2, blob_location3\n",
    "        \n",
    "        # connect to storage account \n",
    "        blob_service_client = connect_blob()\n",
    "        \n",
    "        # input test data\n",
    "        ## 1. hospital csv dataset\n",
    "        container1 = \"hospitals\"\n",
    "        blob_location1 = \"raw_data/facilityprofile_2021-08-10.csv\"\n",
    "        \n",
    "        ## 2. insurance excel dataset\n",
    "        container2 = \"insurance\"\n",
    "        blob_location2 = \"raw_data/CAInsurances.xlsx\"\n",
    "        \n",
    "        ## 3. container/file doesn't exist\n",
    "        container3 = \"patients\"\n",
    "        blob_location3 = \"raw_data/patients.csv\"\n",
    "    \n",
    "    @classmethod\n",
    "    def tearDownClass(cls):\n",
    "        \n",
    "        \n",
    "    def test_spark_session(self):\n",
    "        spark = spark_session()\n",
    "        self.assertIsInstance(spark, SparkSession)\n",
    "        spark.stop()\n",
    "        \n",
    "    def test_connect_blob(self):\n",
    "        blob_service_client = connect_blob()\n",
    "        self.assertIsInstance(blob_service_client, BlobServiceClient)\n",
    "    \n",
    "    def test_get_blob_data(self):\n",
    "        # Case 1: get blob data of hospital csv \n",
    "        container_client1, blob_data1 = get_blob_data(blob_service_client, container1, blob_location1)\n",
    "        self.assertTrue(blob_data1.blob_name == blob_location1)\n",
    "        \n",
    "        # Case 2: get blob data of insurance excel\n",
    "        container_client2, blob_data2 = get_blob_data(blob_service_client, container2, blob_location2)\n",
    "        self.assertTrue(blob_data2.blob_name == blob_location2)\n",
    "        \n",
    "        # Case 3: get non-existent file\n",
    "        self.assertRaises(FileNotFoundError, get_blob_data, blob_service_client, container3, blob_location3)\n",
    "        \n",
    "    def test_blob_to_temp(self):\n",
    "        # Case 1: download hospital csv data to local temp file\n",
    "        self.setup_test_blob_to_temp()        \n",
    "        container_client1, blob_data1 = get_blob_data(blob_service_client, container1, blob_location1)\n",
    "        blob_to_temp('csv', blob_data1)\n",
    "        self.assertTrue(os.path.exists(\"temp.txt\"))\n",
    "        \n",
    "        # Case 2: download insurance excel data to local temp file \n",
    "        self.setup_test_blob_to_temp()        \n",
    "        container_client2, blob_data2 = get_blob_data(blob_service_client, container2, blob_location2)\n",
    "        blob_to_temp('excel', blob_data2)\n",
    "        self.assertTrue(os.path.exists(\"temp.xlsx\"))\n",
    "        \n",
    "        # Case 3: give wrong file format\n",
    "        self.assertRaises(ValueError, blob_to_temp, 'pdf', blob_data2)\n",
    "\n",
    "    def setup_test_blob_to_temp(self):\n",
    "        # delete temp files\n",
    "        try:\n",
    "            os.remove(\"temp.txt\")\n",
    "            os.remove(\"temp.xlsx\")\n",
    "        except OSError:\n",
    "            pass\n",
    "\n",
    "    def test_read_blob_data(self):\n",
    "        # Case 1: hospital csv dataset\n",
    "        container_client1, blob_data1 = get_blob_data(blob_service_client, container1, blob_location1)\n",
    "        blob_to_temp('csv', blob_data1)\n",
    "        pdf1 = read_blob_data('csv', dtype='unicode')\n",
    "        self.assertIsInstance(pdf1, pd.core.frame.DataFrame)\n",
    "        self.assertFalse(pdf1.empty)\n",
    "        \n",
    "        # Case 2: insurance excel dataset\n",
    "        container_client2, blob_data2 = get_blob_data(blob_service_client, container2, blob_location2)\n",
    "        blob_to_temp('excel', blob_data2)\n",
    "        pdf2 = read_blob_data('excel')\n",
    "        self.assertIsInstance(pdf2, pd.core.frame.DataFrame)\n",
    "        self.assertFalse(pdf2.empty)\n",
    "        \n",
    "        # Case 3: give wrong file format \n",
    "        self.assertRaises(ValueError, read_blob_data, 'pdf')\n",
    "        \n",
    "    def test_export_to_blob(self):\n",
    "        # Case 1: Upload local files (downloaded by setup_case1_test_export_to_blob) in test_export_to_blob_data\n",
    "        container_client, folder = self.setup_case1_test_export_to_blob()\n",
    "        export_to_blob(folder, '%s/output' % (folder), container_client)\n",
    "        files = [l for l in container_client.list_blobs(name_starts_with='test_export_to_blob_data/output/')]\n",
    "        filenames = [file['name'].split('/')[-1] for file in files]\n",
    "        self.assertTrue(filenames == ['PPRRVU20_OCT.csv', 'PPRRVU20_OCT.txt', 'PPRRVU20_OCT.xlsx'])\n",
    "        \n",
    "        # Case 2: local folder doesn't exist\n",
    "        self.setup_case1_test_export_to_blob()\n",
    "        folder = 'data'\n",
    "        self.assertRaises(FileNotFoundError, export_to_blob, folder, '%s/output' % (folder), container_client)    \n",
    "        \n",
    "        # Case 3: A file instead of a folder is given\n",
    "        filepath = \"./PPRRVU20_OCT.xlsx\"\n",
    "        self.assertRaises(NotADirectoryError, export_to_blob, filepath, '%s/output' % (folder), container_client)\n",
    "        \n",
    "    def setup_case1_test_export_to_blob(self):\n",
    "        # add files to dbfs\n",
    "        container = \"testdata\"\n",
    "        folder = \"test_export_to_blob_data\"\n",
    "        os.makedirs(folder, exist_ok=True)\n",
    "        container_client = blob_service_client.get_container_client(container)\n",
    "        \n",
    "        for file in ['PPRRVU20_OCT.csv', 'PPRRVU20_OCT.txt', 'PPRRVU20_OCT.xlsx']:\n",
    "            blob_location = \"%s/%s\" % (folder, file)\n",
    "            blob_data = container_client.get_blob_client(blob_location)\n",
    "            with open(blob_location, \"wb\") as blob:\n",
    "                data = blob_data.download_blob()\n",
    "                data.readinto(blob)\n",
    "                blob.close()\n",
    "        return container_client, folder\n",
    "    \n",
    "    def setup_case2_test_export_to_blob(self):\n",
    "        if os.path.exists('data'):\n",
    "            shutil.rmtree('data')\n",
    "    \n",
    "    def test_sheet_names(self):\n",
    "        # set filepath as testdata container\n",
    "        container = \"testdata\"\n",
    "        container_client = blob_service_client.get_container_client(container)\n",
    "        \n",
    "        # Case 1: read excel file\n",
    "        file = \"test_sheet_names_data/20LOCCO.xlsx\"\n",
    "        self.assertEqual(sheet_names((file, container_client)), (\"test_sheet_names_data/20LOCCO.xlsx\" , ['09LOCCO']))\n",
    "        \n",
    "        # Case 2: read empty excel file\n",
    "        file = \"test_sheet_names_data/empty_excel.xlsx\"\n",
    "        self.assertEqual(sheet_names((file, container_client)), (\"test_sheet_names_data/empty_excel.xlsx\" , ['Sheet1']))\n",
    "        \n",
    "        # Case 3: read non-excel file\n",
    "        file = \"test_sheet_names_data/20LOCCO.txt\"\n",
    "        self.assertEqual(sheet_names((file, container_client)), (None, None))\n",
    "\n",
    "    def test_read_files(self):\n",
    "        # set filepath as testdata container\n",
    "        container = \"testdata\"\n",
    "        container_client = blob_service_client.get_container_client(container)\n",
    "        \n",
    "        # Case 1: excel sheet contains target form\n",
    "        file = \"test_read_files/106580996_CDM_All_2020.xlsx\"\n",
    "        sheet = \"Common OP Procedures\"\n",
    "        self.assertEqual(read_files((file, sheet, container_client)), (\"test_read_files/106580996_CDM_All_2020.xlsx\" , \"Common OP Procedures\"))\n",
    "   \n",
    "        # Case 2: excel sheet doesn't contains target form\n",
    "        file = \"test_read_files/106580996_CDM_All_2020.xlsx\"\n",
    "        sheet = \"Hospital CDM\"\n",
    "        self.assertEqual(read_files((file, sheet, container_client)), (None, None))\n",
    "        \n",
    "        # Case 3: non-excel file\n",
    "        file = \"test_read_files/106190521_Comments_2020.docx\"\n",
    "        self.assertEqual(read_files((file, sheet, container_client)), (None, None))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-4bfd57e271a0>:19: ResourceWarning: unclosed <ssl.SSLSocket fd=2344, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=0, laddr=('10.0.0.146', 56519), raddr=('20.60.128.132', 443)>\n",
      "  blob_service_client = connect_blob()\n",
      "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
      "test_blob_to_temp (__main__.TestDataCleaning) ... ok\n",
      "test_connect_blob (__main__.TestDataCleaning) ... ok\n",
      "test_export_to_blob (__main__.TestDataCleaning) ... ok\n",
      "test_get_blob_data (__main__.TestDataCleaning) ... ok\n",
      "test_read_blob_data (__main__.TestDataCleaning) ... ok\n",
      "test_read_files (__main__.TestDataCleaning) ... ok\n",
      "test_sheet_names (__main__.TestDataCleaning) ... ok\n",
      "test_spark_session (__main__.TestDataCleaning) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 8 tests in 14.314s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x1e8973933a0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
